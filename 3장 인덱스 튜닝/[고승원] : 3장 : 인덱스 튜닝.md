# 3장 인덱스 튜닝

# 3.1 테이블 액세스 최소화

랜덤 I/O를 최소화 하기 위한 전쟁을 시작한다.

## 3.1.1 테이블 랜덤 액세스

### 인덱스에 대한 맹신 또는 섣부른 자신감

- 인덱스와 파티션 Pruning의 차이 : 인덱스는 특정 값의 위치를 빨리 찾음 / 파티션은 검색 대상에서 제외함
- 아무리 데이터가 많아도 인덱스를 사용하면 금방 조회된다.
- 대량 데이터를 조회할 때 인덱스를 사용하면 풀테이블 스캔보다 느리다.

### 인덱스 ROWID는 물리적 주소인가? 논리적 주소인가?

![image](https://github.com/user-attachments/assets/15947992-e9c0-4454-8781-8a8f82fdb353)

SQL이 참조하는 컬럼을 인덱스가 모두 포함하는 경우가 아니면 인덱스를 스캔한 후 반드시 테이블에 엑세스 한다.

→ `TABLE ACCESS BY INDEX ROWID` 실행계획

ROWID는 데이터파일 번호, 오브젝트 번호, 블록 번호와 같은 물리적 요소로 이루어져 있다.

하지만 ROWID는 논리적 주소이다 아래 그림처럼 레코드를 찾기 위한 논리적 주소 정보를 담고있기 때문이다.

![image](https://github.com/user-attachments/assets/c6283e5f-f0b8-4a53-8045-e8b00b8b67ba)

보통 인덱스 ROWID를 포인터로 이해하는 경우가 있는데, 정확히 논리적 주소이다.

디스크에서 테이블 레코드를 찾아가기 위한 위치 정보를 담고 있어 레코드와 물리적으로 연결된 구조는 아니다.

### 메인 메모리 DB와 비교

잘 튜닝된 OLTP DB는 버퍼캐시 히트율이 99% 이상이다. 하지만 메모리 DB와 비교하면 속도가 느린데 왜 그런걸까?

- 메모리 DB가 빠른 이유 : 버퍼캐시에 로딩 후 인덱스를 생성하는데 메모리상 주소 즉 포인터를 갖는다.
- 오라클 캐시가 비교적 느린 이유 : 테이블 블록이 수시로 버퍼캐시에 밀려났다가 다시 캐싱되어 인덱스 포인터로 직접 연결이 불가능 하여 디스크 주소 정보(Data Block Address)로 찾아간다.

즉 속도는 물리적 주소 >>>> 논리적 주소 이다.

### I/O 메커니즘 복습

Data Block Address = 데이터파일번호 + 블록번호

I/O 성능을 높이려면 버퍼캐시를 활용해야한다. 그래서 디스크를 읽기 전에 버퍼캐시를 찾아본다.

→ 탐색은 DBA를 해시 함수에 입력해서 해시 체인을 찾는다. → 버퍼 헤더를 찾는다.

- 캐시에 적재할 때와 읽을 때 같은 해시 함수를 사용해서 버퍼 헤더는 항상 같은 해시 체인에 연결된다.
- 실제 데이터가 담긴 버퍼 블록은 매번 다른 위치에 캐싱된다. 메모리 주소값은 버퍼 헤더가 가지고 있다.
- 인덱스로 테이블 블록에 엑세스할 때는 리프 블록에서 얻은 ROWID를 분해해서 DBA 정보를 얻는다.
- TABLE FULL SCAN 할 때는 익스텐트 맵을 통해 읽을 블록들의 DBA 정보를 얻는다.

디스크를 읽기 전에 버퍼캐시를 찾아보고, 없다면 디스크에서 읽어와 해당 블록을 버퍼캐시에 적재한다.

- 모든 데이터가 캐싱되어 있더라도 테이블 레코드를 찾기 위해 매번 DBA 해싱과 래치 획득 과정을 반복한다.
→ Lock에 의한 경합이 발생할 수 있어 생각보다 고비용 작업이다.

### 인덱스 ROWID는 우편주소

디스크 DB가 사용하는 ROWID는 우편주소에, 메모리 DB가 사용하는 포인터는 전화번호에 비유할 수 있다.

즉 속도는 포인터 >>>>  ROWID 이다.

오라클에서 가장 빠른 ROWID 엑세스인 TABLE ACCESS BY INDEX ROWID 실행 계획은 실제론 고비용 연산이다.

## 3.1.2 인덱스 클러스터링 팩터

Clustering Factor : 특정 컬럼을 기준으로 같은 값을 갖는 데이터가 서로 모여있는 정도 (응집률)

클러스터링 팩터가 근접해 있으면 블록 I/O가 줄어서 인덱스 검색 효율이 매우 좋다.

![image](https://github.com/user-attachments/assets/484b88ec-5420-4fb6-9bdb-02a9ce38daa3)

좌 클러스터링팩터 좋음 / 우 클러스터링 팩터 안좋음

### 인덱스 손익분기점

인덱스 ROWID를 이용한 테이블 엑세스는 읽어야할 데이터가 일정량을 넘는 순간 테이블 전체를 스캔하는 것보다 느려진다. 이렇게 느려지는 부분을 인덱스 손익분기점이라고 한다.

Table Full Scan은 데이터 몇 건을 추출하던지 성능은 같다. 반면에 Index Scan은 추출 건수가 늘어나면 성능에 영향이 커진다. 이유는 다음과 같다.

- Table Full Scan은 시퀀셜 액세스이고, 인덱스는 ROWID를 이용한 랜덤 액세스 이다.
- Table Full Scan은 Multiblock I/O고, 인덱스 ROWID는 Single Block I/O이다.

인덱스 손익분기점은 보통 5~20%의 낮은 수준에서 결정된다. (CF에 따라 1~90%로 달라지기도 함)

* 5~20%는 레코드가 100만건 이내의 테이블에나 적용되는 수치이고, 레코드 수가 더 많아지면 손익분기점이 더 낮아진다. 레코드 수가 많아지면 캐시 히트율이 현저히 낮아진다. 또한 CF가 안좋을 확률도 높다.

이처럼 Table Full Scan이 항상 나쁜 것이 아니며, Index Scan이 항상 옳은 것도 아니다.

### 온라인 프로그램 튜닝 vs 배치 프로그램 튜닝

OLTP는 인덱스를 효과적으로 활용하는 방식을 중심으로 처리해야 한다 (NL조인, 인덱스, 소트)

배치는 항상 전체범위 처리 기준으로 튜닝해야 한다. (해시 조인, Full Scan)

```sql
-- 1. 반환되는 데이터 건수가 적은 경우
-- 소량이므로 NL 조인을 사용한다.
select c.고객번호, c.고객명, h.전화번호, h.주소, h.상태코드, h.변경일시
from 고객 c, 고객변경이력 h
where c.실명확인번호 = :rmnno
	and h.고객번호    = c.고객번호
	and h.변경일시 = (select max(변경일시)
									from 고객변경이력 m
									where 고객번호 = c.고객번호
										and 변경일시 >= trunc(add_months(sysdate, -12), 'mm')
										and 변경일시 < trunc(sysdate, 'mm'))
										
	----	----	----	----	----	----	----	----	----	----	----	----	----
0        SELECT STATEMENT Optimizer-ALL_ROWS (Cost= ...)
1   0     NESTED LOOPS
2   1      NESTED LOOPS (Cost= •)
3   2       NESTED LOOPS (Cost= .)
4   3        TABLE ACCESS (BY INDEX ROWID) OF '고객' (TABLE) (Cost= ...)
5   4         INDEX (RANGE SCAN) OF '고객_X01' (INDEX) (Cost= ...)
6   3        VIEW PUSHED PREDICATE OF 'SYS.VW_SQ_1' (VIEW) (Cost= ...)
7   6         SORT (AGGREGATE) (Cost= ...)         
8   7          FIRST ROW (Cost= ...)
9   8           INDEX (RANGE SCAN (MIN/MAX)) OF '고객변경이력_PK' (Cost= ...)
10  2        INDEX (UNIQUE SCAN) OF '고객변경이력_PK' (INDEX (UNIQUE)) (Cost= ...)
11  1       TABLE ACCESS (BY INDEX ROWID) OF '고객변경이력' (TABLE) (Cost= ...)

-- 2. 반환되는 데이터 건수가 많은 경우
-- 대량이므로 Full Scan과 해시 조인을 사용한다.
insert into 고객_임시
select /*+ full(c) full(h) index_ffs(m.고객변경이력)
					ordered no_merge(m) use_hash(m) use_hash(h) */
			c.고객번호, c.고객명, h.전화번호, h.주소, h.상태코드, h.변경일시
from 고객 c, 고객변경이력 h
where c.고객구분코드 = 'A001'
	and h.고객번호    = c.고객번호
	and h.변경일시 = (select max(변경일시)
									from 고객변경이력 m
									where 고객번호 = c.고객번호
										and 변경일시 >= trunc(add_months(sysdate, -12), 'mm')
										and 변경일시 < trunc(sysdate, 'mm'))

	----	----	----	----	----	----	----	----	----	----	----	----	----
0        INSERT STATEMENT Optimizer=ALL_ROWS (Cost= ...)
1   0     LOAD TABLE CONVENTIONAL OF '고객_임시'
2   1      HASH JOIN (Cost=...)
3   2       HASH JOIN (Cost=...)
4   3        TABLE ACCESS (FULL) OF '고객' (TABLE) (Cost= ...)
5   4        VIEW (Cost=...)
6   5         SORT (GROUP BY) (Cost= ...)
7   6          FILTER
8   7           INDEX (FAST FULL SCAN) OF '고객변경이력_PK' (Cost= ...)
9   2        TABLE ACCESS (FULL) OF '고객변경이력' (TABLE) (Cost= ...)

-- 3. 고객변경이력 테이블을 두 번 읽는 것을 없에려면 다음처럼 변경하면 된다.
insert into 고객_임시
select c.고객번호, c.고객명, h.전화번호, h.주소, h.상태코드, h.변경일시
from (select /*+ full(c) full(h) leading9c) use_hash(h) */
		  c.고객번호, c.고객명, h.전화번호, h.주소, h.상태코드, h.변경일시
		  , rank() over (partition by h.고객번호 order by h.변경일시 desc) no
			from 고객 c, 고객변경이력 h
			where c.고객구분코드 = 'A001'
				and h.고객번호    = c.고객번호
				and 변경일시     >= trunc(add_months(sysdate, -12), 'mm')
				and 변경일시     < trunc(sysdate, 'mm'))
where no = 1
```

Full Scan이 Index보다 더 효과적이지만, 상당히 오래 기다려야 하고 시스템에 부담을 준다.

따라서 배치 프로그램에서는 파티션 활용 전략이 매우 중요한 튜닝 요소이고, 병렬 처리까지 고려해야 한다.

위 테이블에선 변경일시로 파티셔닝하면 부담을 줄이기 좋아보인다.

요약 : 모든 성능 문제를 인덱스로 해결하면 안된다. 풀 테이블 스캔과 파티셔닝도 상황에 따라 큰 무기가 된다.

## 3.1.4 인덱스 컬럼 추가

인덱스 컬럼 추가 : 엑세스 최소화를 위해 가장 일반적으로 사용되는 방법이다.

```sql
select /*+ index(emp emp_x01) */ *
from emp
where deptno = 30
	and sal >= 2000
```

index가 (detpno + job) 일 때위와 같은 쿼리를 사용할 때 테이블 액세스 수를 보자

![image](https://github.com/user-attachments/assets/791b1e9e-4498-4e36-8390-3285780bc55e)

depno에 대해서만 인덱스를 활용하기 때문에 랜덤 액세스가 많다.

위 인덱스를 다음과 같이 변경하면 랜덤 액세스를 줄일 수 있다. (deptno + job + sal)

![image](https://github.com/user-attachments/assets/d9a3683e-180f-44e2-9d33-1f1c3ef0a03b)

이와 같이 수정하면 인덱스 스캔 단계에서 얻는 로우수가 줄어든다. → 랜덤 액세스 수 줄어듬

* 테이블 방문 수와 블록 I/O 수를 대조하면 클러스터링 팩터가 어느정도인지 알 수 있다.

## 3.1.5 인덱스만 읽고 처리

테이블 액세스 단계 필터 조건에 의해 버려지는 레코드가 많을 때 인덱스에 컬럼을 추가해서 해결했다.

테이블 액세스 필터에서 버려지는 레코드가 거의 없다면 어떻게 튜닝해야 할까?

→ 쿼리에 사용되는 컬럼을 인덱스에 추가해 테이블 액세스를 아예 없엔다. (Covered 쿼리/인덱스) 

→ Covered 쿼리는 실제 적용하기 곤란한 경우가 많다.

### Include 인덱스

Include 인덱스 : 리프 노드에 인덱스 키 외에 미리 지정한 컬럼을 같이 저장하는 기능 (최대 1023 컬럼)

```sql
create index emp_x01 on emp (deptno) include (sal)
```

인덱스에 include 하는 경우 루트/브랜치 노드에는 저장하지 않고, 리프 블록에만 저장하여 수직적 탐색 및 소트 사용이 불가하다.

→ 랜덤 액세스 줄이는 용도

## 3.1.6 인덱스 구조 테이블

IOT(Index-Organized Table) : 램덤 액세스가 아예 발생하지 않도록 인덱스 구조로 생성한 테이블 (클러스터형 인덱스)

- 테이블을 찾아가기 위한 ROWID와 달리 그 자리에 테이블 데이터를 갖는다. (InnoDB의 PK 인덱스와 같이)
- 만드는 법
    
    ```sql
    create table index_org_t (
    	a number, 
    	b varchar(10), 
    	constraint index_org_t_pk primary key (a) 
    ) organization index or heap(옵션)
    ```
    
- 일반 힙 구조 테이블 인서트는 랜덤방식 이지만 IOT 인서트는 정렬 상태를 유지하며 데이터를 입력한다.
→ 인위적으로 클러스터링 팩터를 좋게 유지해서 범위 검색에 유리하다.
→ 블록 I/O가 현저히 줄어든다.

## 3.1.7 클러스터 테이블

클러스터 테이블에는 인덱스 클러스터와 해시 클러스터 두 가지가 있다.

### 인덱스 클러스터 테이블

클러스터 키 값이 같은 레코드를 한 블록에 모아서 저장한다.

한 블록에 담기지 않으면 새로운 블록을 할당하여 클러스터 체인으로 연결한다.

다중 테이블 클러스터 : 여러 테이블 레코드를 같은 블록에 저장하는 것

오라클 클러스터는 키 값이 같은 데이터를 같은 공간에 저장해 둘 뿐, IOT나 클러스터형 인덱스처럼 정렬하지 않는다.

```jsx
create cluster c_dept# ( deptno number(2) ) index;
```

인덱스 클러스터 테이블 구성하는법

1. 클러스터 생성
2. 클러스터 인덱스 정의
3. 클러스터 테이블 생성

클러스터 인덱스 특징

- 일반 B*Tree 구조를 사용한다.
- 테이블 레코드를 일일이 가리키지 않고 첫 번째 데이터 블록만 가리킨다. (테이블 레코드와 1:M 관계)
- 클러스터 인덱스의 키값은 항상 unique하다. → 랜덤 액세스가 줄어 효율적이다.

### 해시 클러스터 테이블

해시 클러스터는 인덱스를 사용하지 않고 해시 알고리즘을 사용해 클러스터를 찾아간다.

해시 클러스터 테이블 구성하는법

1. 클러스터 생성
2. 클러스터 테이블 생성

# 3.2 부분범위 처리 활용

본 절은 테이블 랜덤 액세스로 인한 손익분기점의 한계를 극복할 히든카드이다.

## 3.2.1 부분범위 처리

DBMS는 클라이언트에게 데이터를 전송할 때 일정량씩 나누어 전송한다.

클라이언트에게 Fetch Call 이 없으면 전송을 대기한다.

따라서 아주 많은 데이터를 읽더라도, 일정량을 전송하고 대기하기 때문에 첫 결과는 빠르게 나온다.

이를 **부분범위 처리**라고 한다.

Java에서의 부분범위 처리 (default 10)

1. rs.next() 호출 시 Fetch Call을 통해 DB로부터 전송받은 데이터를 클라이언트 캐시에 저장한다.
2. rs.next()를 호출할 때 캐시에서 데이터를 읽는다.
3. 캐시 데이터를 모두 소진하면 추가 Fetch Call을 한다.
4. 반복

### 정렬 조건이 있을 때 부분범위 처리

DB 서버는 모든 데이터를 다 읽어 정렬을 마쳐야 클라이언트에게 데이터 전송을 시작할 수 있다.

Sort Area, Temp 테이블스페이스까지 이용해 데이터 정렬을 마치고 나면 그때부터 일정량씩 나눠 클라이언트에게 데이터를 전송한다.

정렬 대상 인덱스가 있으면 부분범위 처리가 가능하다. (정렬 처리를 따로 하지 않기 때문)

### Array Size 조정을 통한 Fetch Call 최소화

대량 데이터를 받으면 Array Size를 크게, 그렇지 않다면 작게 설정하는게 좋다.

```sql
show arraysize
```

### 쿼리 툴에서 부분범위 처리

쿼리 툴도 동일하게 Array Size가 있어, 반환 데이터가 많은 쿼리여도 빠르게 응답하는 모습을 볼 수 있다.

Array Size 외에도 Initial Fetch를 설정하여 첫 Fetch를 N번 할 수 있다.

특정 쿼리 툴에선 추가 요청을 하지 않아도 계속 출력해준다.

## 3.2.2 부분범위 처리 구현

```java
public class PartialRange {

	public static int fetch(ResultSet rs, int arraysize) throws Exception {
		int i = 0;
		while(rs.next()) {
			System.out.println(rs.getLong(1) +": "+ rs.getString(2));
			//array size가 넘어가면 멈춘다.
			if(++i >= arraysize) return i;
		}
		return i;
	}

	public static void execute (Connection con) throws Exception {
		int arraysize = 10;
		String SQLStmt = "select object_id, object_name from all_objects";
		Statement stmt = con.createStatement();
		stmt.setFetchSize(arraysize);
		ResultSet rs = stmt.executeQuery(SQLStmt);
		while(true){
			//사용자 요청이 있으면 데이터를 fetch한다.
			int r = fetch(rs, arraysize);
			if(r < arraysize) break;
			System.out.println("Enter to Continue... (Q)uit? ");
			BufferedReader in = new BufferedReader(new InputStreamReader(System.in)):
			String input = in.readLine();
			if(input.equals("Q")) break;
		}
		rs.close(); 
		stmt.close();
	}
	
	public static void main(String(] args) throws Exception {
		Connection con = getConnection();
		execute(con):
		releaseConnection(con);
	}
```

## 3.2.3 OLTP 환경에서 부분범위 처리에 의한 성능개선 원리

Online Transaction Processing으로 온라인 트랜잭션을 처리하는 시스템을 말한다.

따라서 일반적으로 소량 데이터를 읽고 갱신한다.

만일 OLTP 시스템에서 대량의 데이터를 조회하려면 수많은 테이블 랜덤 액세스가 발생하게 된다.

보통 대량의 데이터를 전부 보지 않고, 정렬된 일부만 열람하기 때문에 인덱스를 이용해 정렬을 생략하고, fetch된 일부만 보여줄 수 있다.

게시판을 예로 들자

```java
select 게시글ID, 제목, 작성자, 등록일시
from 게시판
where 게시판구분코드 = 'A'
order by 등록일시 desc
```

인덱스를 (게시판구분코드 + 등록일시)로 구성하지 않으면 정렬을 생략할 수 없다.

### 멈출 수 있어야 의미있는 부분범위 처리

부분범위 처리의 핵심은 **앞쪽 일부만 출력하고 멈출 수 있는가** 이다.

- 쿼리 툴은 그렇게 구현 되어 있다. (2- tier)
- 클라이언트와 db사이에 was, ap 서버가 있는 n-tier는 쿼리가 끝나면 커넥션을 바로 반환해야 하므로 구현하기 어렵다.
- 그렇다고 불가능한건 아니다.

### 배치 I/O

- 인덱스 ROWID를 이용한 테이블 랜덤 액세스는 고비용 구조이다.
- 조회 데이터양이 많아지면 I/O도 함께 많아져 성능이 급격히 나빠진다.
    
    → 상위 N개 집합을 부분범위 처리를 사용하면 빠른 응답속도를 낼 수 있다. 따라서 인덱스 소트는 매우 중요하다.
    

배치 I/O는 위와 같은 상황에서 디스크 랜덤 I/O 성능을 높이려고 만든 기능이다.

- 캐시 미스로 테이블 블록에 액세스 해야 하는 상황에 바로 하지 않는다.
- 일정 블록 액세스가 쌓이면 한꺼번에 액세스 한다. (12c부터 ROWID로 액세스 하는 부분은 작동)

### 데이터 정렬 이슈

배치 I/O 기능이 작동하면 데이터 정렬 순서가 매번 다를 수 있다.

→ 버퍼 캐시 히트률이 100%가 안되기 때문이다.

실제로 배치 I/O를 사용하게 되면 SORT ORDER BY 실행계획이 추가된다.

![image](https://github.com/user-attachments/assets/f7a123ae-43c8-4f1e-abdf-14039bde5822)

위처럼 배치 I/O는 정렬을 따로 수행하기 때문에, order by가 없는 쿼리에서 유용하게 사용할 수 있다.

오라클 12c로 업데이트 되면서 정렬 순서가 달라지므로 인덱스를 통한 정렬을 사용하는 전략은 구식이 되었다.

그러니, order by를 추가해 정렬하는 것이 바람직하며 5.3에 소트 연산 생략 방법이 있으니 확인하길 바란다.

# 3.3 인덱스 스캔 효율화

## 3.3.1 인덱스 탐색

![image](https://github.com/user-attachments/assets/00abd42a-cf7d-45d9-958e-0f71a6382f94)

위  인덱스에서 아래 조건절을 처리할 때 어느 지점에서 스캔을 시작하고, 멈추는지 알아보자

1. 

```java
WHERE C1 = 'B'
AND C2 <= 3
```

![image](https://github.com/user-attachments/assets/3b50d108-b901-49da-a499-5f07769eb890)

루트 블록에서 B3를 찾고 그 왼쪽의 브랜치로 간다. 

B로 시작하는 레코드를 찾고, 시퀀셜 스캔을 하다가 C를 만나는 순간 스캔은 종료된다.

1. 

```java
WHERE C1 = 'B'
AND C2 = 3
```

![image](https://github.com/user-attachments/assets/b040e5f7-6d4c-424b-9070-2f54fdfa2c96)

루트 블록에서 B3를 찾고 그 왼쪽의 브랜치로 간다. 

B로 시작하는 레코드를 찾고, 4를 만나는 순간 스캔은 종료된다.

1. 

```java
WHERE C1 = 'B'
AND C2 >= 3
```

![image](https://github.com/user-attachments/assets/b8fda511-4749-479e-bc9f-a96cdc4abd18)

4.

```java
WHERE C1 BETWEEN 'A' AND 'C'
AND C2 BETWEEN 2 AND 3
```

![image](https://github.com/user-attachments/assets/ad2b667d-73bd-4b60-bc4f-318c5f5a37ac)

C1 조건절은 스캔 시작과 끝 지점을 결정하는데 중요한 역할을 했지만, C2는 스캔양을 줄이는데 아무것도 안했다. 

## 3.3.2 인덱스 스캔 효율성

![image](https://github.com/user-attachments/assets/30e62403-fd46-4ffa-9ed7-6a54f1e1176e)

다음와 같은 용어사전에서 이런 쿼리가 발생하면 어떨까?

1. 성능검으로 시작하는 용어 검색 → 성능검사부터 성능계수까지
2. 성능으로 시작하고, 네 번째 문자가 ‘선’인 용어 검색 → 전체 스캔

**각 문자를 잘라서 인덱스를 생성하면 어떻게 될까?**

1. 성능검으로 시작하는 용어 검색 → 성능검사부터 성능계수까지
2. 성능으로 시작하고, 네 번쨰 문자가 ‘선’인 용어 검색 → 전체 스캔

인덱스가 있음에도 스캔양이 많은 이유는 선행 컬럼인 3번 째 문자가 조건절에 없기 떄문이다 

### 인덱스 스캔 효율성 측정

SQL 트레이스를 보면 된다.

![image](https://github.com/user-attachments/assets/90b86f28-397f-4232-a48a-027dcd886b85)

인덱스 스캔을 통해 얻은 레코드가 10개 인데, 7463블록을 읽은 사실을 알 수 있다. (cr)

## 3.3.3 액세스 조건과 필터 조건

인덱스 액세스 조건 : 인덱스 스캔 범위를 결정하는 조건

인덱스 필터 조건 : 테이블로 액세스할지 결정하는 조건

테이블 필터 조건 : 쿼리 수행 다음 최종 결과집합에 포함 여부 조건

옵티마이저의 비용 계산 원리 : 수직적 탐색 + 수평적 탐색 + 랜덤 액세스 + 루트와 브랜치에서 읽는 블록 수 + 리프 블록 스캔 수 + 액세스 과정에서 읽는 블록 수

![image](https://github.com/user-attachments/assets/04313477-d4dc-44e7-bdbf-9838e3f37c23)

성능검사 필터링에선 ‘성’, ‘능’이 액세스 조건이고, ‘선’이 필터 조건이다.

## 3.3.4 비교 연산자 종류와 컬럼 순서에 따른 군집성

인덱스 컬럼을 앞쪽부터 = 연산자로 조회하면 결과 집합 레코드는 모두 모여있다.

= 조건이 아니거나, 컬럼이 누락되면 레코드가 서로 흩어진 상태가 된다.

인덱스 스캔 범위는 선행 컬럼이 모두 = 조건인 상태에서 **첫 번째 나타나는 범위 검색 조건**이 인덱스 스캔 범위를 결정한다.

**인덱스 컬럼에 대한 조건절은 모두 액세스 조건에 표시된다.** (비록 스캔 범위를 못줄여도)

- 좌변 컬럼을 가공한 조건절
- 왼쪽 % 또는 양쪽 %를 사용한 like 조건절
- 같은 컬럼에 대한 조건절이 두 개 이상일 때, 인덱스 액세스 조건으로 선택되지 못한 조건절
- OR Expansion, INLIST ITERATOR로 선택되지 못한 OR, IN 절

* 인덱스 필터 조건도 스캔량을 줄이는데 어느정도 역할을 하는데, 대게 무시할만한 수준이다.

## 3.3.5 인덱스 선행 컬럼이 등치(=) 조건이 아닐 때 생기는 비효율

인덱스 스캔은 조건절이 모두 = 조건일 때 가장 좋다. (뒤쪽 컬럼은 없어도, =가 아니어도 됨)

→ 스캔한 모든 레코드 그대로 결과집합

인덱스 스캔 중간에 BETWEEN절이 있다면 어떻게 될까?

![image](https://github.com/user-attachments/assets/94eade81-f316-4823-a10a-a2c0772b053c)

![image](https://github.com/user-attachments/assets/14b26db1-1176-4769-bb4e-4d9f847e7792)

조건을 만족하지 않는 레코드까지 스캔하고서 버리는 비효율이 생긴다.

## 3.3.6 BETWEEN을 IN-List로 전환

범위 검색 컬럼이 맨 뒤로 가는게 좋지만, 그럴 수 없으면 IN절로 바꾸면 된다.

![image](https://github.com/user-attachments/assets/b7fd7b55-122b-41b4-8079-a9f5e54840de)

![image](https://github.com/user-attachments/assets/6d93259b-bfda-4e96-ae5a-aeb5113d23be)

인덱스 수직 탐색이 세 번 발생한다. 

→ = 조건 쿼리가 세 번 발생 + UNION ALL 한 것과 같다.

→ Index Skip Scan도 고려해보자.

→ IN 조건의 항목 수가 늘어나면 NL 조인 또는 서브쿼리로 구현하자.

### BETWEEN 조건을 IN-List로 전환할 때 주의 사항

- IN  개수가 많으면 수직적 탐색이 많이 발생해 비효율이 커진다.
- N개의 조건이 멀리 떨어져 있을 때만 유용하다.

![image](https://github.com/user-attachments/assets/47ff2083-3a0e-404c-ad62-6c24850560bc)

## 3.3.7 Index Skip Scan 활용

```java
SELECT COUNT(*)
FROM table t
WHERE 판매구분 = 'A'
AND 판매월 BETWEEN '201801' and '201812'
```

쿼리를 최적으로 수행하려면 = 조건인 판매구분으로 시작하는 인덱스를 생성해야 한다.

하지만 판매구분의 카디널리티는 높지 않다. 따라서 판매월, 판매구분으로 인덱스를 구성하고 힌트를 줘보자

→ 이럴땐 IN절로 변경하는게 블록 I/O가 더 적어진다.

→ Skip Scan을 사용하면 IN절보다 더 적은 블록 I/O 수를 갖게 된다.

## 3.3.8 IN 조걸은 =인가?

IN과 = 조건은 다르다.

```java
SELECT *
FROM 고객별가입상품
WHERE 고객번호 = cust_no
AND 상품 ID in ('a', 'b', 'c')
```

고객별로 세 건의 상품을 가입할 때, (상품ID, 고객번호)로 인덱스를 생성하면 같은 상품은 고객번호 순으로 정렬된다. 반면에 고객번호 기준으로는 산개된다.

- IN 조건이 더 효율적인 경우 (= 조건과 동일, 반드시 이렇게 풀려야만 한다.)
    
    ![image](https://github.com/user-attachments/assets/74633e15-6c39-4b12-82e9-2b666f8c77a3)

    
- IN 조건을 잘못 적용한 경우 (블록 I/O 4 에서 9로 증가, 인덱스 필터로 사용하는게 더 효율적이다.)
    
    ![image](https://github.com/user-attachments/assets/874ad7a2-590f-4389-986b-867ace1e6bae)

    

### NUM_INDEX_KEYS 힌트 활용

IN-List 액세스 조건을 필터 조건으로 유도하는 방법

인덱스는 (고객번호, 상품ID)로 구성되어 있다.

```java
select /*+ num_index_keys(a 고객별가입상품_x1 1) */ *
from 고객별가입상품 a
where 고객번호 := cust_no
and 상품ID in ('a', 'b', 'c')
```

고객번호만 액세스 하기 위한 힌트로 힌트의 세 번째 인자 1은 첫 번째 컬럼만 액세스 조건으로 사용하라는 뜻이다.

또는 상품ID 컬럼을 일부러 가공하여 인덱스 조건이 되지 않도록 하는 방법도 있다.

## 3.3.9 BETWEEN과 LIKE 스캔 범위 비교

보통 BETWEEN 보다 LIKE를 더 자주 사용한다. 왜냐? 편하기 때문

하지만, 이건 틀렸다. BETWEEN 보다 LIKE를 쓰게 되면, 인덱스 스캔량이 달라질 수 있다. (부정적으로)

→ BETWEEN을 쓰게 되면 적어도 손해는 안본다.

```sql
WHERE 판매월 BETWEEN '201901' AND '201912'
AND 판매구분 = 'B'

WHERE 판매월 LIKE '2019%'
AND 판매구분 = 'B'

-- 아래가 훨씬 더 비효율적임
```

![image](https://github.com/user-attachments/assets/ab66ea8b-3321-4615-99ce-1591a17981e5)

## 3.3.10 범위검색 조건을 남용할 때 생기는 비효율

동적 쿼리를 LIKE로 구사하는 경우가 종종 있다.

```sql
SELECT 고객ID, 상품명, 지역코드 ..
FROM 가입상품
WHERE 회사코드 = com
AND 지역코드 LIKE :reg || '%'
AND 상품명 LIKE :prod || '%'
-- 지역코드는 동적쿼리
```

지역코드에 이렇게 LIKE문을 사용하게 되면 `:reg` 가 null일 때도 인덱스 스캔 범위가 줄어들지 않는다.

위의 방식은 개발 생산성은 좋지만, 인덱스 스캔 효율이 좋지 않다.

## 3.3.11 다양한 옵션 조건 처리 방식의 장단점 비교

### OR 조건 활용

```sql
SELECT * FROM 거래
WHERE (:id is null or ID = :id)
AND 거래일자 BETWEEN :dt1 AND :dt2
```

위의 쿼리는 옵티마이저에 의한 OR Expansion 쿼리 변환이 기본적으로 작동하지 않으므로 (고객ID + 거래일자) 인덱스를 사용할 수 없다.

→ 따라서 인덱스 선두 컬럼에 대한 옵션 조건에 OR 조건을 사용해선 안된다. 

→ 인덱스 액세스 조건으로도 사용할 수 없다.

→ 테이블 액세스 단계에서 필터링한다. (테이블 랜덤 액세스 다하고 필터링 = 비효율적)

* 단 인덱스에 포함되지 않은 컬럼 옵션은 어차피 테이블 필터링이어서 사용해도 상관없다.

**OR 조건 사용 해도될 때**

- 인덱스 액세스 조건으로 사용 불가
- 인덱스 필터 조건으로 사용 불가
- 테이블 필터 조건으로만 사용 가능
- 인덱스 구성 컬럼 중 하나 이상이 NotNull 컬럼이면 18c부터 인덱스 필터 조건으로 사용 가능

**요약**

유일한 장점은 옵션 컬럼이 NULL 허용 컬럼이어도 결과집합을 보장한다.

### LIKE/BETWEEN 조건 활용

선두 인덱스가 충분 하다면 LIKE/BETWEEN 조건을 인덱스 필터 조건으로 사용해도 충분히 좋은 성능을 낼 수 있다.

선두 인덱스의 변별력이 충분하지 않다면 성능 문제가 생긴다.

LIKE/BETWEEN을 사용하면 안될 때

- 인덱스 선두 컬럼 (비효율)
- NULL 허용 컬럼 (결과 집합 오류)
- 숫자형 컬럼 (자동 형변환)
- 가변 길이 컬럼 (결과 집합에 추가됨)

### UNION ALL 활용

UNION ALL을 통해 동적 쿼리 중 하나만 실행될 수 있도록 한다.

```sql
SELECT * FROM 거래
WHERE :cust_id is null
AND 거래일자 BETWEEN :dt1 AND :dt2
UNION ALL
SELECT * FROM 거래
WHERE :cust_id is not null
AND 고객ID = :cust_id
AND 거래일자 BETWEEN :dt1 AND :dt2
```

이렇게 쿼리를 구성하면 :cust_id가 어떻든 인덱스를 가장 최적으로 사용할 수 있다.

### NVL/DECODE 함수 활용

동적 쿼리를 구성할 때 NVL, DECODE 어떤걸 쓰든지 실행계획은 똑같다. → OR Expansion 쿼리변환

즉, 위의 UNION ALL 쿼리와 동일한 효과를 낸다.

단점

- LIKE 패턴처럼 NULL 허용 컬럼에 사용 불가.
- 변별력이 가장 좋은 컬럼 하나에만 OR Expansion이 일어난다.

## 3.3.12 함수호출부하 해소를 위한 인덱스 구성

### PL/SQL 함수의 성능적 특성

PL/SQL 사용자 정의 함수는 생각보다 느리다. 이유는 다음과 같다.

- VM에서 실행되는 인터프리터 언어
- 호출마다 Context Switching 발생
- **내장 SQL에 대한 Recursive Call 발생 (가장 부하)**

PL/SQL은 Java 처럼 Bytecode를 생성해서 Data dictionary에 저장하고 가상머신에서 실행한다.

따라서 Native 코드보다 많이 느리다.

다행히 부하를 줄일 수 있는 방법이 있다. 그중 하나가 액세스 조건을 고려한 인덱스 구성이다.

### 효과적인 인덱스 구성을 통한 함수호출 최소화

```sql
SELECT /*+ full(a) */ 회원번호, 회원명, 생년, 생월일, 등록일자
FROM 회원 a
WHERE 생년 = '1987'
AND 암호화된_전화번호 = encryption(:phone_no)

1. (생년) 인덱스 -> 생년을 만족하는 만큼 encryption 수행
2. (생년, 생월일, 암호화된_전화번호) 인덱스 -> 생월일이 없어 생년을 만족하는 만큼 encryption 수행
3. (생년, 암호화된_전화번호) 인덱스 -> 단 한 번 수행
```
