# 3장 인덱스 튜닝

## 3.1 테이블 액세스 최소화

### 3.1.1 테이블 랜덤 액세스

- 테이블 랜덤 액세스가 성능에는 어느정도 영향을 줄까?

#### 인덱스에 대한 맹신 또는 섣부른 자신감
- 파티션 Prunning이 필요한 이유? 혹은 인덱스로 검색하는데도 느린 이유는 뭘까?
  - 결론부터 말하면 아무리 빠르게 데이터를 찾더라도(위치를) **`디스크에서 데이터를 가져오는 행위가 매우 느리고 비용이 많이 드는 작업`** 이기 때문에 성능에 미치는 영향이 큼

#### 인덱스 ROWID는 물리적 주소? 논리적 주소?
- SQL이 참조하는 컬럼을 인덱스가 모두 포함하는 경우(커버링 인덱스)가 아니면 원하는 자료를 찾기 위해 **`인덱스를 스캔한 후에 반드시 ROWID로 테이블에 액세스 해야함`**

![CleanShot 2024-07-31 at 23 35 15](https://github.com/user-attachments/assets/ee8cfb3d-ac64-4d54-85c6-cc56cde25a88)

- 인덱스를 스캔하는 이유는 검색 조건을 만족하는 소량의 데이터를 인덱스에서 빠르게 찾고, 거기서 테이블 레코드를 찾아가기 위한 주소값, 즉 ROWID를 얻으려는데 목적이 있음
- 인덱스의 ROWID는 포인터(물리적 주소)가 아님. **`논리적 주소에 가까움`**
  - 테이블 레코드를 찾아가기 위한 논리적 정보를 담고 있기 때문, 디스크 상에서 바로 엑세스 가능한 실제 물리적 위치를 나타내지는 않음
  - 찾아가기 위한 상대적 주소를 가지고 있을 뿐, 직접 연결된 구조는 아님
  - 따라서, **`디스크 주소 정보를 이용해 해시 알고리즘으로 버퍼 블록을 찾아가는 과정이 수반됨(버퍼 캐시 먼저 검색, 등)`**
    - 해당 과정은 캐시버퍼 체인 래치와 버퍼 Lock에 대한 경합이 발생할 수 도 있듯이 생각보다 고비용의 작업임

  - 메모리 DB의 인덱스는 포인터이기 때문에 메모리의 물리적 주소가 맞음

    ![CleanShot 2024-07-31 at 23 39 31](https://github.com/user-attachments/assets/30ec6c63-7f75-4958-ba8c-dcea9928367b)

    ![CleanShot 2024-07-31 at 23 43 41](https://github.com/user-attachments/assets/c00eee01-39b8-4d64-aa43-9173f9201910)

      - ROWID를 분해해서 DBA 정보 확인
      - 해싱 결과로 해시 체인 찾기(래치 획득)
      - 해시 체인 내부에서 버퍼 헤더 찾기(버퍼 캐시의 메모리 주소)
      - 버퍼 헤더가 있으면 포인터로 버퍼 블록 찾아가기
      - 버퍼 헤더가 없으면 디스크에서 데이터 파일 → 블록 → 레코드 찾아가서 캐시에 로딩 & 결과 리턴

- 우편과 전화의 비교를 생각하면 이해하기 쉬움

#### Table Full Scan I/O
- 테이블 세그먼트 헤더에 익스텐트 맵 확인
- 익스텐트 맵을 통해 각 익스텐트의 첫 번째 블록 DBA를 알 수 있음
- 익스텐트 내부의 블록은 연결되어 있으므로 시퀀셜하게 읽으면됨

### 3.1.2 인덱스 클러스터링 팩터
- **`특정 컬럼을 기준으로 같은 값을 갖는 데이터가 서로 모여있는 정도`**
  - 군집성 계수(Clustering Factor, CF)

- CF가 좋은 컬럼에 생성한 인덱스는 검색 효율이 좋음
  - **`인덱스 레코드 정렬 순서와 실제 테이블 정렬 순서가 비슷하기 때문에 테이블 액세스량에 비해 블록 I/O가 적게 발생함`**
    → `버퍼 Pinning` (인덱스 ROWID로 테이블 액세스 할 때, 래치 획득과 체인 스캔 후 블록에서 데이터를 읽고 포인터 그대로 유지)
      - 다음에 읽을 테이블 블록과 직전에 읽은 테이블 블록의 주소가 같기만 하면 됨

        ![CleanShot 2024-07-31 at 23 54 57](https://github.com/user-attachments/assets/7bfc9650-e279-4590-8cdd-3c84b6bcb6c4)

  - **`CF가 좋은 경우`**

    ![CleanShot 2024-07-31 at 23 52 41](https://github.com/user-attachments/assets/77f3d5db-90d3-4c54-911a-00d6996da2f2)

  - **`CF가 좋지 않은 경우`**

    ![CleanShot 2024-07-31 at 23 53 30](https://github.com/user-attachments/assets/e6a358ee-fc7d-48ab-be20-3bf30d00b9a5)

### 3.1.3 인덱스 손익분기점
- 인덱스의 ROWID로 테이블 액세스하는 것은 생각보다 **고비용 구조** 임
  → 즉, **`읽어야 할 데이터가 일정량 이상 넘어가면 테이블 풀스캔이 효과적이게 됨`**

- Index Range Scan에 의한 테이블 액세스가 Table Full Scan보다 느려지는 지점을 **`인덱스 손익분기점`** 이라고 함
  - 보통 10~100만건 이내 테이블에서 손익 분기점은 5~20% 수준, BCHR, CF에 따라 달라짐 (1000만건을 넘어가면 더 낮아질 수 있음, 실제 개수에도 영향을 받음)
    - Index Range Scan은 랜덤 액세스 방식에 Single Block I/O라서 데이터를 한번에 많이 가져올 수 없음
  - Table Full Scan은 1000건을 조회하든, 1000만건을 조회하든 성능이 일정함
    → 시퀀셜 액세스, Multiblock I/O라 한번에 대량 데이터를 가져오는데 매우 유리함

  ![CleanShot 2024-08-01 at 00 18 03](https://github.com/user-attachments/assets/15a497d8-7d4d-4f81-8dc7-7a5227e97ab4)

- 이는 **`인덱스 스캔이 항상 좋은 것은 아니라는 의미`**. 그렇다고 이를 높이기 위해 어떤 조치를 취해야 하는 것은 아님
- **OLTP 프로그램과 Batch성 프로그램의 튜닝의 특징을 구분 짓는 핵심 개념 **

#### OLTP 튜닝 vs 배치 프로그램 튜닝
- **`OLTP 튜닝`**
  - 소량 데이터를 읽고 갱신하므로 인덱스를 효과적으로 활용하는 것이 중요함
  - NL 조인 사용
  - 인덱스로 소트 연산 생략

- **`배치 프로그램 튜닝`**
  - 전체범위 처리 기준으로 튜닝해야함
  - 처리 대싱 집합 중 일부를 빠르게 처리하는 것이 아니라 전체를 빠르게 처리하는 것을 목표로 해야함
  - 대량 데이터를 빠르게 처리하려면 Full Scan과 해시 조인이 유리함
  - 초대용량 테이블을 Full Scan하면 오래 걸리기 때문에 배치 프로그램은 파티션 활용 전략이 매우 중요한 튜닝 요소
  - 파티션 테이블을 조회할때는 인덱스를 사용하는 것은 성능이 그다지 좋지 않음
  - 파티셔닝은 Full Scan을 빠르게 처리하기 위함
 
- 모든 성능 문제를 인덱스로 해결하려 해서는 안됨
- 인덱스는 단지 큰 테이블에서 아주 적은 일부 데이터를 빨리 찾고자 할 때 주로 사용하는 도구일 뿐

### 3.1.4 인덱스 컬럼 추가
- **테이블 액세스 최소화를 위해 가장 일반적으로 사용하는 튜닝 기법은** **`기존 인덱스에 컬럼 추가 하는 것`**
  - 다만, 실 운영 환경에서는 인덱스 구성을 변경하기 쉽지 않기 때문에 적절하게 판단해야함
 
- 인덱스를 마구 추가하는 것은 관리 비용이 증가하고, DML 부하에 따른 트랜잭션 성능 저하, 개수 제한 등의 여러 문제가 있기 때문에 함부로 추가하지 않는 것이 좋음

- **인덱스 스캔 후, 테이블 액세스 과정에서 필터되는 데이터가 많은 경우 사용**
 - **인덱스 스캔량 자체는 줄지 않지만 테이블 랜덤 액세스 횟수를 줄여줄 수 있음**

  ![CleanShot 2024-08-01 at 00 31 44](https://github.com/user-attachments/assets/66d0934f-7c46-48c2-a9d3-c8a52c5da67f)

  ![CleanShot 2024-08-01 at 00 31 12](https://github.com/user-attachments/assets/a7c34624-1009-40e7-935d-b706d5eff61d)

  - cr: Consistent Read(Consistent Read Mode로 버퍼 캐시에서 특정 블록을 읽는 것)
  - pr: Physical Read(특정 블록을 읽어서 버퍼 캐시에 로딩)

### 3.1.5 인덱스만 읽고 처리
- 테이블 랜덤 액세스가 아무리 많아도 필터 조건에 의해 버려지는 레코드가 거의 없다면 비효율적인 부분은 없는 것

- 이런한 경우에는 쿼리에 사용되는 컬럼을 모두 인덱스에 추가해서 테이블 액세스가 아예 발생하지 않도록 하는 방법을 고려해볼 수 있음
  - 인덱스만 읽어서 처리하는 쿼리를 **`Covered 쿼리`** , 해당 쿼리에 사용된 인덱스를 **`Covered 인덱스`** 라고 함
  - 방법은 좋으나 추가해야 할 컬럼이 많은 경우에는 실제로 적용하기에는 어려움

#### Include 인덱스
- 인덱스 키 외에 미리 지정한 컬럼을 리프 레벨에 함께 저장하는 기능
  - 최대 1023 컬럼까지 지정 가능
  - SQL Server 2005 버전에 추가된 기능

- 커버드 인덱스와 달리 수직적 탐색에 사용할 수 없음. 정렬도 되지 않음
- 순전히 테이블 랜덤 액세스를 줄이는 용도로 개발됨

### 3.1.6 인덱스 구조 테이블
- **`클러스터형 인덱스`**, **`IOT(Index-Organized Table)`**
  - 랜덤 액세스가 발생하지 않도록 인덱스 구조로 생성된 테이블 

    ![CleanShot 2024-08-01 at 00 38 57](https://github.com/user-attachments/assets/eac78504-0570-4452-a7ca-cc5be2d42f7d)

- **`인덱스 리프 블록에서 테이블 블록에 있어야 할 데이터를 모두 저장`**
  - 인덱스 리프 블록 = 테이블 블록 
- 인위적으로 클러스터링 팩터를 좋게 만드는 방법 → 시퀀셜 데이터 액세스 가능해짐
  - 정렬 상태를 유지하면서 데이터 입력함
  - BETWEEN이나 부등호 조건으로 넓은 범위를 읽을 때 유리함 
- 테이블 생성할 때, `organization index` 작성(기본 테이블은 힙 구조 테이블)

  ![CleanShot 2024-08-01 at 00 41 07](https://github.com/user-attachments/assets/e8d04768-18b5-46a3-ba15-e7d81de2c2cb)

  ![CleanShot 2024-08-01 at 00 41 23](https://github.com/user-attachments/assets/f0ad9008-8b97-4b8c-8c2d-3ef70a273cfd)


### 3.1.7 클러스터 테이블
- 인덱스 클러스터와 해시 클러스터 두가지 종류가 존재함

- **`인덱스 클러스터 테이블`**
  - 클러스터 키 값이 같은 레코드를 한 블록에 모아서 저장하는 구조
  - 한 블록에 모두 담을 수 없을 때는 새로운 블록 할당하여 클러스터 체인으로 연결함
  - 심지어, 여러 테이블 레코드를 같은 블록에 저장할 수도 있음 → 다중 테이블 클러스터 (일반 테이블은 하나의 데이터 블록을 여러 테이블이 공유할 수 없는것과 다름)

    ![CleanShot 2024-08-01 at 00 45 58](https://github.com/user-attachments/assets/80c65187-e5e9-4fbb-b5a1-2bf7b4edd4de)

  - **키 값이 같은 데이터를 같은 공간에 저장해 둘 뿐, IOT나 클러스터 인덱스와는 다름 (정렬된 상태 X)**
 
  - 클러스터 생성

    ![CleanShot 2024-08-01 at 01 00 58](https://github.com/user-attachments/assets/ddf9a5b1-60df-4406-aaf0-ea94beb8c9d6)

  - 클러스터 인덱스 정의

    ![CleanShot 2024-08-01 at 01 01 12](https://github.com/user-attachments/assets/90842892-4e93-4e8f-9a05-cebcc9f565cc)

      - 클러스터에 테이블을 담기 전에 먼저 클러스터 인덱스를 반드시 정의해야함
      - 클러스터 인덱스는 데이터 검색 용도 뿐 아니라 데이터가 저장될 위치를 찾을 때도 사용하기 때문
   
  - 클러스터 테이블 생성

     ![CleanShot 2024-08-01 at 01 00 45](https://github.com/user-attachments/assets/5389a573-fbee-47b4-b784-b88cb9324054)

  - 클러스터 인덱스도 일반 B*Tree 인덱스 구조를 사용하지만, 테이블 레코드를 일일이 가리키지 않고 해당 키 값을 저장하는 첫 번째 데이터 블록을 가리킨다는 점이 다름
    - 즉, 일반 테이블에 생성한 인덱스 레코드는 테이블 레코드와 1:1 대응 관계를 갖지만 클러스터 인덱스는 테이블 레코드와 1:M의 관계를 가짐
    - 따라서, 클러스터 인덱스의 키 값은 항상 유니크함  

      ![CleanShot 2024-08-01 at 01 00 29](https://github.com/user-attachments/assets/55096722-4cba-4bb1-83d6-42cafb9a7a00)

      - 이러한 구조적 특성 때문에 클러스터 인덱스를 스캔하면서 값을 찾을 때는 랜덤 액세스가 값 하나당 한 번씩 밖에 발생하지 않음
        - 클러스터 체인을 스캔하면서 발생하는 랜덤 액세스 제외 
        
  - `클러스터에 도달한 후에는 시퀀셜 방식으로 스캔하기 때문에 넓은 범위를 읽더라도 비효율이 없다는 것이 핵심`

  - 클러스터 인덱스로 조회할 때 실행 계획
    
    ![CleanShot 2024-08-01 at 01 02 25](https://github.com/user-attachments/assets/bbd8253f-ecc9-4f06-ae1f-1ebb2062dbfa)


- **`해시 클러스터 테이블`**
 - 인덱스 클러스터 테이블과는 해시 알고리즘을 사용해 클러스터를 찾아간다는 점만 다름

  ![CleanShot 2024-08-01 at 00 48 59](https://github.com/user-attachments/assets/92131788-f4aa-42e0-882e-4adfbc6ae0db)

  ![CleanShot 2024-08-01 at 00 49 19](https://github.com/user-attachments/assets/4bc760b8-7a68-4d86-adf2-734719a21e94)

## 3.2 부분범위 처리 활용

### 3.2.1 부분범위 처리
- **`데이터를 전송할 때 일정량씩 나누어 전송하는 방식`**

- 다만, `정렬 조건이 있으면 정렬을 완료한 후 전송할 데이터를 나눌 수 있기 때문에 성능 개선이 불가능함`
  - 정렬 조건이 인덱스의 선두에 있으면 부분 범위 처리 가능함
    - 인덱스에서 조회하는 순서대로 전달하면 되기 때문에 전체 확인 및 정렬 작업 없이 나누어 전송 가능하기 때문

- 대량 데이터를 파일로 내려받는다면 어차피 데이터를 모두 전송해야 하므로 Array Size를 크게 하고 Fetch Call을 줄임
- 일부 데이터만 Fetch하다가 멈추는 프로그램은 Array Size를 작게 설정하는 것이 유리함

- **Pagination 전략과 동일한 것 같음**

### 3.2.2 부분범위 처리 구현
- 모든 DBMS는 데이터를 나눠서 전송함. 이 특징을 이용하여 중간에 멈췄다가 사용자의 추가 요청이 있을때마다 데이터를 가져오도록 하는 것은 구현하는 개발자의 몫
- Array Size에 도달하면 멈추었다가 사용자 요청이 있을 때 다시 데이터를 Fetch하는 부분이 필요함
- 보통은 Framework에서 제공하는 기능으로 구현함

### 3.2.3 OLTP 환경에서 부분범위 처리에 의한 성능개선 원리
- 클라이언트 - DB 서버 2-Tier 환경은 일부만 출력하고 멈출 수 있음
- 클라이언트와 DB 사이에 WAS, AP 서버 등이 존재하는 n-Tire는 클라이언트가 특정 DB 커텍션을 독점할 수 없기 때문에 구현하기 어려움 → 5.3장에서 방법 설명함

