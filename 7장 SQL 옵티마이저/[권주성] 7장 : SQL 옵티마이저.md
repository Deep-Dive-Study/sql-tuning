# 7장 SQL 옵티마이저

## 7.1 통계정보와 비용 계산 원리

### 7.1.1 선택도와 카디널리티
- **`선택도(Selectivity)`** : 전체 레코드 중 조건절에 의해 선택되는 레코드 비율
  - '=' 조건으로 검색 할 때 경우는 선택도 는 `1 / NDV`
    - NDV : 컬럼값 종류 개수(성별이라면 남/여 - 2)
  - 즉, 컬럼값이 다양할 수록 (유니크할 수록) 선택도는 **낮아짐**

- **`카디널리티(Cardinality)`** : 전체 레코드 중에서 조건절에 의해 선택되는 레코드 개수
  - `카디널리티 = 총 로우 수 * 선택도 = 총 로우 수 / NDV`
  - 카디널리티랑 선택도는 비례 관계

- 옵티마이저는 카디널리티를 구하고, 이를 통해서 비용을 계산하여 옵티마이징 방식(테이블 액세스방식, 조인 순서/방식, 등)을 결정함
- 비용을 계산하는 출발점은 선택도. 선택도를 잘못 계산하게되면 비효율적인 방식을 선택하게 될수 있음
- 따라서, `카디널리티값의 기초가 되는 선택도 값의 계산이 매우 중요`함
  - `선택도를 계산할 때 NDV를 사용하므로 통계정보 수집 과정에서 이 값을 정확하게 구하는 것`도 덩달아 중요하게됨
  - 즉, `통계정보 수집주기, 샘플링 비율 등을 잘 결정해야하는 이유`임!  

### 7.1.2 통계정보
- 통계 정보는 **`오브젝트 통계`** 와 **`시스템 통계`** 가 있음
  - 오브젝트 통계
    - 테이블 통계
    - 인덱스 통계
    - 컬럼 통계(히스토그램 포함) 
  - 시스템 통계 

#### 테이블 통계
- 테이블 통계 수집
```sql
  BEGIN
    dbms_stats.gather_table_stats('scott', 'emp');
  END;
/
```

- 테이블 통계 조회
```sql
  SELECT 
    num_rows, -- 총 레코드 계수
    blocks, -- 테이블 블록 수 = '사용된' 익스텐트에 속한 총 블록 수
    avg_row_len, -- 레코드당 평균 길이(Bytes)
    sample_size, -- 샘플링한 레코드 수
    last_analyzed -- 통계정보 수집일시
  FROM all_tables
  WHERE owner='SCOTT'
  AND table_name = 'EMP';
```

#### 인덱스 통계
- 인덱스 통계 수집
```sql
-- 인덱스 통계만 수집
  BEGIN
    dbms_stats.gather_index_stats(ownname => 'scott', indname => 'emp_x01');
  END;
/

-- 테이블 통계를 수집하면서 인덱스 통계도 같이 수집
  BEGIN
    dbms_stats.gather_table_stats('scott', 'emp', cascade=>true);
  END;
/
```

- 인덱스 통계 조회
```sql
  SELECT
    blevel, -- 브랜치 레벨. 인덱스 루트에서 블록에 도달하기 직전까지 읽게되는 블록 수
    leaf_blocks,  -- 인덱스 리프 블록 총 개수
    num_rows, -- 인덱스에 저장된 레코드 개수
    distnct_keys, -- 인덱스 키값의 조합으로 만들어지는 값의 종류 개수. c1(3) * c2(4) = 12. 선택도 계산에 사용
    avg_leaf_blocks_per_key, -- 인덱스 키값을 모두 '=' 조건으로 조회할 때 읽게 될 리프 블록 개수
    avg_data_blocks_per_key, -- 인덱스 키값을 모두 '=' 조건으로 조회할 때 읽게 될 테이블 블록 개수
    clustering_factor, -- 인덱스 키값 기준으로 테이블 데이터가 모여 있는 정도. 인덱스를 스캔하면서 테이블 레코드를 찾을 때 읽게 될 테이블 블록 개수를 미리 계산 한 수치
    sample_size,
    last_analyzed
  FROM all_indexes
  WHERE owner = 'SCOTT'
  AND table_name = 'EMP'
  AND index_name = 'EMP_X01';
```

#### 컬럼 통계
- 컬럼 통계 수집
  - 컬럼 통계는 테이블 통계 수집할 때 함께 수집됨 

- 컬럼 통계 조회

```sql
  SELECT
    num_distinct, -- 컬럼 값의 종류 개수(NDV)
    density, -- '=' 조건일 때 선택도. 1/NDV
    avg_col_len, -- 컬럼 평균 길이(bytes)
    low_value, -- 최소값
    high_value, -- 최대값
    num_nulls, -- null 인 레코드 수
    last_analyzed,
    sample_size
  FROM all_tab_columns
  WHERE owner = 'SCOTT'
  AND table_name = 'EMP'
  AND column_name = 'DEPTNO';
```

#### 컬럼 히스토그램
- '=' 조건 선택도는 1/NUM_DISTINCT 공식으로 구하거나 미리 구해둔 DENSITY 값을 활용하면 됨
  - 일반적으로는 잘 들어맞지만, 데이터 분포가 균열하지 않은 컬럼은 그렇지 못함
  - 이런 경우, 옵티마이저는 통계 외에도 히스토그램 사용함

**`히스토그램(Histogram)`** : 컬럼 값 별로 데이터 비중이나 빈도를 미리 계산해 놓은 통계정보. 실제 테이터를 읽어서 계산해 둔 값.

<img width="381" alt="CleanShot 2024-10-13 at 20 02 42@2x" src="https://github.com/user-attachments/assets/449a5781-287d-4d28-be36-cfed7d637c74">

- 히스토그램 유형
  - 도수분포 : 값별로 빈도수 저장
  - 높이균형 : 각 버킷의 높이가 동일하도록 데이터 분포 관리
  - 상위도수분포 : 많은 레코드를 가진 상위 n개 값에 대한 빈도수 저장
  - 하이브리드 : 도수분포와 높이균형 특성 결합

- 히스토그램 수집

```sql
  BEGIN
    dbms_stats.gather_table_stats('scott', 'emp', cascade=>false, method_opt=>'for columns ename size 10, deptno size 4' );
  END;
/
```

- 히스토그램 조회

```sql
  SELECT endpoint_value, endpoint_number
  FROM all_histograms
  WHERE owner = 'SCOTT'
  AND table_name = 'EMP'
  AND column_name = 'DEPTNO'
  ORDER BY endpoint_value;
```

  <img width="202" alt="CleanShot 2024-10-13 at 20 06 08@2x" src="https://github.com/user-attachments/assets/b2ff3b53-6b77-4fca-b54c-bbf07e68449c">

#### 시스템 통계
- 시스템 통계란, **`애플리케이션 및 하드웨어 성능 특성을 측정한 것`**
  - CPU 속도
  - 평균 Single Block I/O 속도
  - 평균 Multiblock I/O 속도
  - 평균 Multiblock I/O 개수
  - I/O 서브시스템의 최대 처리량(Throughput)
  - 병렬 Slave의 평균적인 처리량(Throughput)

- 과거에는 옵티마이저가 이러한 항목을 고려하지 않고 상수처리하였음
- 현재는 시스템 사양뿐만 아니라 애플리케이션 특성 및 동시 트랜잭션 발생량에 따라서도 이들 특성이 변하기 때문에
- 이러한 하드웨어 및 어플리케이션 특성을 반영할 수 있게 되었음

- sys.aux_stats$ 뷰에서 조회할 수 있음

  <img width="359" alt="CleanShot 2024-10-13 at 19 34 30@2x" src="https://github.com/user-attachments/assets/2413f0fc-190c-403c-af69-8f817d43ceab">

### 7.1.3 비용 계산 원리
- 단일 테이블을 인덱스로 액세스할 때의 비용 계산 원리

  - '=' 조건 검색 시

    ``` 
    비용 = BLEVEL                     -- 인덱스 수직적 탐색 비용
          + AVG_LEAF_BLOCKS_PER_KEY  -- 인덱스 수평적 탐색 비용
          + AVG_DATA_BLOCKS_PER_KEY  -- 테이블 랜덤 액세스 비용
    ```      

    - blevel : 브랜치 레벨. 인덱스 루트에서 블록에 도달하기 직전까지 읽게되는 블록 수
    - avg_leaf_blocks_per_key : 인덱스 키값을 모두 '=' 조건으로 조회할 때 읽게 될 리프 블록 개수
    - avg_data_blocks_per_key : 인덱스 키값을 모두 '=' 조건으로 조회할 때 읽게 될 테이블 블록 개수


  - '=' 조건 검색 아닐 시(아래 컬럼 통계까지 활용)

    ```   
     비용 = BLEVEL                                  -- 인덱스 수직적 탐색 비용
          + LEAF_BLOCKS       * 유효 인덱스 선택도    -- 인덱스 수평적 탐색 비용
          + CLUSERING_FACTOR  * 유효 테이블 선택도    -- 테이블 랜덤 액세스 비용
    ```

    - leaf_blocks  : 인덱스 리프 블록 총 개수
    - clustering_factor : 인덱스 키값 기준으로 테이블 데이터가 모여 있는 정도. 인덱스를 스캔하면서 테이블 레코드를 찾을 때 읽게 될 테이블 블록 개수를 미리 계산 한 수치
    - 유효 인덱스 선택도 : 전체 인덱스 레코드 중 액세스 조건에 의해 선택될 것으로 예상되는 레코드 비중
    - 유효 테이블 선택도 : 전체 인덱스 레코드 중 인덱스 컬럼에 대한 모든 조건절에 의해 선택 될 것으로 예상되는 레코드 비중

#### 비용(Cost)의 정확한 의미
- 방금 전까지 설명한 비용 계산식은 `I/O 비용 모델` 기준임
  - 예상 I/O Call 횟수
- 반면, `최신 CPU 비용 모델` 에서 Cost는 Single Block I/O를 기준으로 한 `상대적 시간`을 표현함
  - 예를 들어 Cost 100은 우리 시스템에서 Single Block I/O 100번 하는 정도의 시간
  - 같은 실행계획으로 같은 양의 데이터를 읽어도 애플리케이션 및 하드웨어 성능 특성에 따라 절대 소요시간이 다를 수 있기 때문에 개발함
  - 그리고 똑같은 I/O Call이더라도 Single 혹은 Multi Block인지에 따라 속도가 다르며, 같은 Block I/O라더라도 시스템마다 차이가 있을 수 있음

## 7.2 옵티마이저에 대한 이해

### 7.2.1 옵티마이저의 종류
- **비용기반 옵티마이저(CBO, Cost-Based Optimizer)**
  - 사용자 쿼리를 위해 후보군이 될 만한 실행 계획들을 도출하고 데이터 딕셔너리에 미리 수집해 둔 통계정보를 이용해 각 실행 계획의 예상 비용을 산정하고 그 중 가장 낮은 비용의 실행 계획 중 하나를 선택하는 옵티마이저
  - CBO가 사용하는 통계 정보
    - 데이터량
    - 컬럼 값의 수
    - 컬럼 값 분포
    - 인덱스 높이
    - 클러스터링 팩터
    - 등

- **규칙기반 옵티마이저(RBO, Rule-Based Optimizer)**
  - RBO는 데이터 특성을 나타내는 통계정보를 전혀 활용하지 않고, 우선순위 규칙에 따라 실행계획을 만드는 옵티마이저
  - 최근에는 전혀 사용되지 않음
   
### 7.2.2 옵티마이저 모드
- **`ALL_ROWS`** : 전체 처리속도 최적화
  - 쿼리 결과집합 '전체를 읽는 것을 전제로' 시스템 리소스를 가장 적게 사용하는 실행계획을 선택
- **`FIRST_ROWS`** : 최초 응답속도 최적화
  - 옵티마이저 전체 결과 집합 중 앞쪽 일부만 읽다가 멈추는 것을 전제로 응답속도가 가장 빠른 실행계획을 선택
  - 현재는 쓰이지 않고 First Rows N으로 대체됨
- **`FIRST_ROWS_N`** : 최초 N건 응답속도 최적화
  - 옵티마이저는 사용자가 앞쪽 N 로우만 읽고 멈추는 것을 전제로 응답속도가 가장 빠른 실행계획을 선택 

### 7.2.3 옵티마이저에 영향을 미치는 요소
- SQL 과 연산자 형태
- 인덱스, IOT, Cluster, partition, MV 등 옵티마이저 팩터
- 제약 설정
- 통계 정보
  - 통계 정보가 실제 데이터를 반영하지 못하고 있는 경우, 비효율적인 쿼리가 발생할 수 있음 
- 옵티마이저 힌트
- 옵티마이저 관련 파라미터
### 7.2.4 옵티마이저의 한계
- 옵티마이저도 사람이 만든 소프트웨어이니 실수가 발생할 수 있음
- 옵티마이저 행동에 가장 큰 영향을 미치는 통계 정보를 '필요한 만큼 충분히' 확보하는 것부터가 어려운 일임 
  - 정보가 많을 수록 좋지만, 그만큼 수집하고 관리하는데 시간과 비용이듬. 트레이드 오프 관계

- 통계 정보가 아무리 완벽해도 바인드 변수를 사용한 SQL에 컬럼 히스토그램 정보를 활용할 수 없음
- 따라서, 앞으로도 옵티마이저는 좋아질 수는 있으나 불완전할 수 밖에 없음

### 7.2.5 개발자의 역할
- 옵티마이저에 의존하지 말고 개발자 스스로 옵티마이저가 되어야 함
  - 능력이 없어서 맡기는게 아니라, 바빠서 맡긴다고 생각하길
  - 즉, 옵티마이저가 어떻게 행동할지, 하고 있는지(동작원리)를 알고 있어야함
 
- '내 프로그램은 내가 지킨다' 는 장인 정신이 필요함

- **`필요한 최소 블록만 읽도록 쿼리 작성`**
  - SQL 작성자 스스로 결과 집합을 논리적으로 잘 정의하고, 그 결과집합을 만들기 위해 DB 프로세스가 최소한의 일만 하도록 쿼리를 효율적으로 작성하는 것이 무엇보다 중요
  - 데이터 베이스 성능은 I/O 효율에 달려있음 - 필요한 최소 블록만 읽도록 해야함
    - 요새 드는 생각이 성능 향상은 곧 비용 절감이라고 생각이듬
      - 동일 성능 대비해서 리소스가 적게 들기 때문에
  - 통계정보에 담긴 힘든 업무적 특성까지 고려하여 SQL을 작성하는 것은 누가 뭐래도 개발팀의 역할임 

- **`최적의 옵티마이저 팩터 제공`**
  - 최적화는 옵티마이저가 수행하지만, 잘 할 수 있도록 적절한 수단을 제공하는 것은 사용자의 몫임
  - 대표적인 옵티마이저 팩터
    - 전략적인 인덱스 구성
    - DBMS 가 제공하는 다양한 기능 활용
    - 옵티마이저 모드 설정
    - 정확하고 안정적인 통계 정보
  - 정리하면, 옵티마이저 모드를 포함해 각종 파라미터를 적절한 값으로 설정하고, 통계정보를 잘 수집해주는 것이 무엇보다 중요함
    - 이것이 기본이 된 상태에서, 전략적인 인덱스 구성이 필수적으로 뒷받침 되어야함
    - 그리고, DBMS가 제공하는 기능을 적극적으로 활용하여 옵티마이저가 최적의 선택을 할 수 있도록 다양한 수단을 제공해주어야함 

- **`필요하면 힌트를 활용하여 최적의 액서스 경로 유도`**

### 7.2.6 튜닝 전문가 되는 공부방법
- 데이터베이스 튜닝이란?
  - DBMS 성능 튜닝
  - 즉, SQL이 병목이나 지연 없이 빠르고 안정적으로 수행되도록 조치하는 모든 활동 

- **`데이터베이스 튜닝에서 다루는 큰 세가지`**
  - SQL 튜닝 : I/O 효율화, DB Call 최소화, SQL 파싱 최소화, 등
  - DB 설계 : 논리적 데이터 구조 설계, 물리적 저장 구조 설계, 등
  - 인스턴스 튜닝 : Lock/Latch 모니터링 및 해소, 메모리 설정, 프로세스 설정, 등

  <img width="480" alt="CleanShot 2024-10-13 at 21 13 58@2x" src="https://github.com/user-attachments/assets/75760f00-11b2-45af-9ab6-e368232987c0">

- 데이터베이스 중심 vs SQL 중심
  - DBA 팀, SQL 튜닝 팀
  - 최근에는 이러한 구분이 많이 희미해진 듯

